{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5de6a3",
   "metadata": {},
   "source": [
    "# Emojify! üòä\n",
    "Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. \n",
    "Rather than writing:\n",
    ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"   \n",
    "\n",
    "The emojifier can automatically turn this into:\n",
    ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
    "\n",
    "We'll implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence (‚öæÔ∏è).\n",
    "\n",
    "### Using Word Vectors to Improve Emoji Lookups\n",
    "* In many emoji interfaces, you need to remember that ‚ù§Ô∏è  is the \"heart\" symbol rather than the \"love\" symbol. \n",
    "    * In other words, you'll have to remember to type \"heart\" to find the desired emoji, and typing \"love\" won't bring up that symbol.\n",
    "* You can make a more flexible emoji interface by using word vectors!\n",
    "* When using word vectors, you'll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate additional words in the test set to the same emoji.\n",
    "    * This works even if those additional words don't even appear in the training set. \n",
    "    * This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set. \n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2135e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.emoji_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b47c8",
   "metadata": {},
   "source": [
    "## Dataset EMOJISET\n",
    "\n",
    "We have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings).\n",
    "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
    "\n",
    "<img src=\"images/notebook_utils/data_set.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7e657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('datasets/emoji/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('datasets/emoji/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e927f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45f72e",
   "metadata": {},
   "source": [
    "Run the following cell to print sentences from X_train and corresponding labels from Y_train. \n",
    "* Change `idx` to see different examples. \n",
    "* Note that due to the font used by iPython notebook, the heart emoji may be colored black rather than red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2aeab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÑ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n",
      "she did not answer my text  üòû\n",
      "Your stupidity has no limit üòû\n",
      "how many points did he score ‚öæ\n",
      "my algorithm performs poorly üòû\n",
      "I got approved üòÑ\n",
      "Stop shouting at me üòû\n",
      "Sounds like a fun plan ha ha üòÑ\n",
      "no one likes him üòû\n",
      "the game just finished ‚öæ\n",
      "I will celebrate soon üòÑ\n"
     ]
    }
   ],
   "source": [
    "for idx in range(20):\n",
    "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791dbec",
   "metadata": {},
   "source": [
    "## Overview of the Model\n",
    "#### Inputs and Outputs\n",
    "* The input of the model is a string corresponding to a sentence (e.g. \"I love you\"). \n",
    "* The output will be a probability vector of shape (1,5), (indicating that there are 5 emojis to choose from).\n",
    "* The (1,5) probability vector is passed to an argmax layer, which extracts the index of the emoji with the highest probability.\n",
    "\n",
    "#### One-hot Encoding\n",
    "* To get your labels into a format suitable for training a softmax classifier, convert $Y$ from its current shape  $(m, 1)$ into a \"one-hot representation\" $(m, 5)$, \n",
    "    * Each row is a one-hot vector giving the label of one example.\n",
    "    * Here, `Y_oh` stands for \"Y-one-hot\" in the variable names `Y_oh_train` and `Y_oh_test`: \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970ba57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b49bc6",
   "metadata": {},
   "source": [
    "Now, see what `convert_to_one_hot()` did. Feel free to change `idx` to print out different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa51688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
      "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(f\"Sentence '{X_train[50]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
    "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5840320",
   "metadata": {},
   "source": [
    "## Implementing Emojifier\n",
    "\n",
    "As shown in Figure 2 (above), the first step is to:\n",
    "* Convert each word in the input sentence into their word vector representations.\n",
    "* Take an average of the word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65b12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('datasets/emoji/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ec810",
   "metadata": {},
   "source": [
    "We've loaded:\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary \n",
    "    - (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n",
    "\n",
    "Run the following cell to check if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847bd23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "idx = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbe3f2",
   "metadata": {},
   "source": [
    "### Sentence to Average\n",
    "1. Convert every sentence to lower-case, then split the sentence into a list of words. \n",
    "2. For each word in the sentence, access its GloVe representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0277890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a valid word contained in the word_to_vec_map. \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    \n",
    "    # Split sentence into list of lower case words\n",
    "    words = sentence.lower().split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros(word_to_vec_map['a'].shape)\n",
    "    \n",
    "    # Initialize count to 0\n",
    "    count = 0\n",
    "    \n",
    "    # Average the word vectors. You can loop over the words in the list \"words\".\n",
    "    for w in words:\n",
    "        \n",
    "        # Check that word exists in word_to_vec_map\n",
    "        if w in word_to_vec_map:\n",
    "            avg += word_to_vec_map[w]\n",
    "            \n",
    "            # Increment count\n",
    "            count +=1\n",
    "          \n",
    "    if count > 0:\n",
    "        # Get the average. But only if count > 0\n",
    "        avg = avg / count\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6f1d2",
   "metadata": {},
   "source": [
    "## Implement the Model\n",
    "We now have all the pieces to finish implementing the `model()` function! \n",
    "After using `sentence_to_avg()` you need to:\n",
    "* Pass the average through forward propagation\n",
    "* Compute the cost\n",
    "* Backpropagate to update the softmax parameters\n",
    "\n",
    "* The equations you implemented in the forward pass and to compute the cross-entropy cost are below:\n",
    "* The variable $Y_{oh}$ (\"Y one hot\") is the one-hot encoding of the output labels. \n",
    "\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Y_{oh,k}^{(i)} * log(a^{(i)}_k)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b05b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a valid word contained in the word_to_vec_map \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "        \n",
    "    # Initialize cost. It is needed during grading\n",
    "    cost = 0\n",
    "    \n",
    "    # Define number of training examples\n",
    "    m = Y.shape[0]                             # number of training examples\n",
    "    n_y = len(np.unique(Y))                    # number of classes  \n",
    "    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Convert Y to Y_onehot with n_y classes\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations): # Loop over the number of iterations\n",
    "        for i in range(m):          # Loop over the training examples\n",
    "            \n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
    "            cost = np.sum(Y_oh[i] * np.log(a))\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emoji_utils.py\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b92494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5, 0, 0, 5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and have drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is surprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49c451",
   "metadata": {},
   "source": [
    "Run the next cell to train your model and learn the softmax parameters (W, b). **The training process will take about 5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d0e4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = -1.643110354841643\n",
      "Accuracy: 0.42424242424242425\n",
      "Epoch: 100 --- cost = -0.07189452751102986\n",
      "Accuracy: 0.9242424242424242\n",
      "Epoch: 200 --- cost = -0.04355357948900457\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = -0.03489614813571813\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace08308",
   "metadata": {},
   "source": [
    "Great! Your model has pretty high accuracy on the training set. Now see how it does on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d27854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49c53d",
   "metadata": {},
   "source": [
    "* Random guessing would have had 20% accuracy, given that there are 5 classes. (1/5 = 20%).\n",
    "* This is pretty good performance after training on only 127 examples.\n",
    "\n",
    "#### The Model Matches Emojis to Relevant Words\n",
    "In the training set, the algorithm saw the sentence \n",
    ">\"I love you.\" \n",
    "\n",
    "with the label ‚ù§Ô∏è. \n",
    "* You can check that the word \"adore\" does not appear in the training set. \n",
    "* Nonetheless, let's see what happens if you write \"I adore you.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31d674fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcbb2ed",
   "metadata": {},
   "source": [
    "#### Word Ordering isn't Considered in this Model\n",
    "* Note that the model doesn't get the following sentence correct:\n",
    ">\"not feeling happy\" \n",
    "\n",
    "* This algorithm ignores word ordering, so is not good at understanding phrases like \"not happy.\" \n",
    "\n",
    "#### Confusion Matrix\n",
    "* Printing the confusion matrix can also help understand which classes are more difficult for your model. \n",
    "* A confusion matrix shows how often an example whose label is one class (\"actual\" class) is mislabeled by the algorithm with a different class (\"predicted\" class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47353ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    0    0    7    7\n",
      "All          9    9   18   13    7   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef318327",
   "metadata": {},
   "source": [
    "# Making it better\n",
    "You're going to build an LSTM model that takes word **sequences** as input! This model will be able to account for word ordering. \n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7271f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c1dd8",
   "metadata": {},
   "source": [
    "## Model Overview\n",
    "\n",
    "<img src=\"images/notebook_utils/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "\n",
    "### Keras and Mini-batching \n",
    "You want to train Keras using mini-batches. However, most deep learning frameworks require that all sequences in the same mini-batch have the **same length**. \n",
    "\n",
    "This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it's just not possible to do them both at the same time.\n",
    "    \n",
    "#### Padding Handles Sequences of Varying Length\n",
    "* The common solution to handling sequences of **different length** is to use padding.  Specifically:\n",
    "    * Set a maximum sequence length\n",
    "    * Pad all sequences to have the same length. \n",
    "    \n",
    "### The embedding layer\n",
    "In Keras, the embedding matrix is represented as a \"layer.\"\n",
    "\n",
    "* The embedding matrix maps word indices to embedding vectors.\n",
    "    * The word indices are positive integers.\n",
    "    * The embedding vectors are dense vectors of fixed size.\n",
    "    * A \"dense\" vector is the opposite of a sparse vector. It means that most of its values are non-zero.  As a counter-example, a one-hot encoded vector is not \"dense.\"\n",
    "* The embedding matrix can be derived in two ways:\n",
    "    * Training a model to derive the embeddings from scratch. \n",
    "    * Using a pretrained embedding.\n",
    "    \n",
    "#### Inputs and Outputs to the Embedding Layer\n",
    "\n",
    "* The `Embedding()` layer's input is an integer matrix of size **(batch size, max input length)**. \n",
    "    * This input corresponds to sentences converted into lists of indices (integers).\n",
    "    * The largest integer (the highest word index) in the input should be no larger than the vocabulary size.\n",
    "* The embedding layer outputs an array of shape (batch size, max input length, dimension of word vectors).\n",
    "\n",
    "* The figure shows the propagation of two example sentences through the embedding layer. \n",
    "    * Both examples have been zero-padded to a length of `max_len=5`.\n",
    "    * The word embeddings are 50 units in length.\n",
    "    * The final dimension of the representation is  `(2,max_len,50)`. \n",
    "\n",
    "<img src=\"images/notebook_utils/embedding1.png\" style=\"width:700px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d2bd2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I\n",
      "1 like\n",
      "2 learning\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate([\"I\", \"like\", \"learning\"]):\n",
    "    print(idx, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa3efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            \n",
    "            # if w exists in the word_to_index dictionary\n",
    "            if w in word_to_index:\n",
    "            \n",
    "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                \n",
    "                # Increment j to j + 1\n",
    "                j += 1\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98184606",
   "metadata": {},
   "source": [
    "Run the following cell to check what `sentences_to_indices()` does, and take a look at your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48217d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices =\n",
      " [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba02826",
   "metadata": {},
   "source": [
    "#### Build Embedding Layer\n",
    "\n",
    "Now you'll build the `Embedding()` layer in Keras, using pre-trained word vectors. \n",
    "\n",
    "* The embedding layer takes as input a list of word indices.\n",
    "    * `sentences_to_indices()` creates these word indices.\n",
    "* The embedding layer will return the word embeddings for a sentence. \n",
    "\n",
    "### Pretrained Embedding Layer\n",
    "1. Initialize the embedding matrix as a numpy array of zeros.\n",
    "    * The embedding matrix has a row for each unique word in the vocabulary.\n",
    "        * There is one additional row to handle \"unknown\" words.\n",
    "        * So vocab_size is the number of unique words plus one.\n",
    "    * Each row will store the vector representation of one word. \n",
    "        * For example, one row may be 50 positions long if using GloVe word vectors.\n",
    "    * In the code below, `emb_dim` represents the length of a word embedding.\n",
    "2. Fill in each row of the embedding matrix with the vector representation of a word\n",
    "    * Each word in `word_to_index` is a string.\n",
    "    * word_to_vec_map is a dictionary where the keys are strings and the values are the word vectors.\n",
    "3. Define the Keras embedding layer. \n",
    "    * Use [Embedding()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding). \n",
    "    * The input dimension is equal to the vocabulary length (number of unique words plus one).\n",
    "    * The output dimension is equal to the number of positions in a word embedding.\n",
    "    * Make this layer's embeddings fixed.\n",
    "        * If you were to set `trainable = True`, then it will allow the optimization algorithm to modify the values of the word embeddings.\n",
    "        * In this case, you don't want the model to modify the word embeddings.\n",
    "4. Set the embedding weights to be equal to the embedding matrix.\n",
    "    * Note that this is part of the code is already completed for you and does not need to be modified! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9557ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1              # adding 1 to fit Keras embedding\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]    # define dimensionality of your GloVe word vectors (= 50)\n",
    "      \n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_size, emb_dim)\n",
    "    \n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70a58fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][1] = 0.39031\n",
      "Input_dim 400001\n",
      "Output_dim 50\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
    "print(\"Input_dim\", embedding_layer.input_dim)\n",
    "print(\"Output_dim\",embedding_layer.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998e01f",
   "metadata": {},
   "source": [
    "## Emojify 2.0\n",
    "This function builds a Keras graph of the architecture shown in Figure (3). \n",
    "\n",
    "* The model takes as input an array of sentences of shape (`m`, `max_len`, ) defined by `input_shape`. \n",
    "* The model outputs a softmax probability vector of shape (`m`, `C = 5`). \n",
    "\n",
    "* You may need to use the following Keras layers:\n",
    "    * [Input()](https://www.tensorflow.org/api_docs/python/tf/keras/Input)\n",
    "        * Set the `shape` and `dtype` parameters.\n",
    "        * The inputs are integers, so you can specify the data type as a string, 'int32'.\n",
    "    * [LSTM()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
    "        * Set the `units` and `return_sequences` parameters.\n",
    "    * [Dropout()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "        * Set the `rate` parameter.\n",
    "    * [Dense()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "        * Set the `units`, \n",
    "        * Note that `Dense()` has an `activation` parameter.  For the purposes of passing the autograder, please do not set the activation within `Dense()`.  Use the separate `Activation` layer to do so.\n",
    "    * [Activation()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation)\n",
    "        * You can pass in the activation of your choice as a lowercase string.\n",
    "    * [Model()](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
    "        * Set `inputs` and `outputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7822a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    # It should be of shape input_shape and dtype 'int32' (as it contains indices, which are integers).\n",
    "    sentence_indices = Input(shape=input_shape, dtype=np.int32)\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors\n",
    "    embedding_layer =  pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X) \n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # The returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128)(X)\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Propagate X through a Dense layer with 5 units\n",
    "    X = Dense(5, activation='linear')(X)\n",
    "    \n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f3d0f",
   "metadata": {},
   "source": [
    "Run the following cell to create your model and check its summary. \n",
    "\n",
    "* Because all sentences in the dataset are less than 10 words, `max_len = 10` was chosen.  \n",
    "* You should see that your architecture uses 20,223,927 parameters, of which 20,000,050 (the word embeddings) are non-trainable, with the remaining 223,877 being trainable. \n",
    "* Because your vocabulary size has 400,001 words (with valid indices from 0 to 400,000) there are 400,001\\*50 = 20,000,050 non-trainable parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b9f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 20,223,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03612e1f",
   "metadata": {},
   "source": [
    "As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics you want to use. Compile your model using categorical_crossentropy loss, adam optimizer and ['accuracy'] metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f0ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebd992",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "752b1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175393c3",
   "metadata": {},
   "source": [
    "Fit the Keras model on `X_train_indices` and `Y_train_oh`, using `epochs = 100` and `batch_size = 32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f57e2d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 6.9732e-04 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 7.8155e-04 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 6.7024e-04 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 6.8292e-04 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 7.9856e-04 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 4.2157e-04 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 5.3217e-04 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 5.5313e-04 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 5.1787e-04 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 6.2833e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 5.0526e-04 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 5.4353e-04 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 5.1113e-04 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 5.8683e-04 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 4.3816e-04 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 7.1065e-04 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 4.8926e-04 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 4.3252e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 3.4402e-04 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 5.0573e-04 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 6.3456e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 5.2196e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 3.7590e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 5.7032e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 6.5071e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 6.7565e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 4.7402e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 3.8084e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 6.8637e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 3.6447e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 4.8515e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 5.5927e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 4.8564e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 3.6892e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 4.0986e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 3.5887e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 4.0737e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.8290e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 3.4392e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 4.2360e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 4.4674e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 5.2685e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 3.1896e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 3.5940e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 3.2159e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.5730e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 2.8919e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 3.5230e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 3.0047e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 3.5592e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 3.0144e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 2.3659e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 2.5705e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 3.9535e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 4.3888e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 2.7489e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 2.4718e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.7823e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 2.6175e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 2.8309e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 3.9851e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 2.7702e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 2.6870e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.7343e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.7063e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 3.1377e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 3.2021e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 2.2758e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 3.3489e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 1.8866e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.1573e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 3.0620e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 2.8786e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 2.9013e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.0846e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 2.2348e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.9768e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 2.7436e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 139ms/step - loss: 2.6000e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 1.8190e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 1.9613e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 2.2437e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 2.0839e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 2.4639e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 2.3306e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 2.4554e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 1.7031e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.2088e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 2.2423e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 2.8251e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 2.7038e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 1.6401e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.1305e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 2.0723e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.1689e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.0773e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 1.6488e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 1.8635e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 2.0393e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 2.6445e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162a25908e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 100, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35dd72",
   "metadata": {},
   "source": [
    "Run the following cell to evaluate your model on the test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09a5d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5821 - accuracy: 0.7679\n",
      "\n",
      "Test accuracy =  0.7678571343421936\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62e5d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòÑ prediction: he got a very nice raise\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: she got me a nice present\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: he is a good friend\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: work is hard\tüòÑ\n",
      "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
      "Expected emoji:üç¥ prediction: any suggestions for dinner\tüòÑ\n",
      "Expected emoji:üòÑ prediction: you brighten my day\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: she is a bully\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: My life is so boring\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: will you be my valentine\tüòû\n",
      "Expected emoji:üòÑ prediction: What you did was awesome\tüòû\n",
      "Expected emoji:üòû prediction: go away\t‚öæ\n",
      "Expected emoji:üç¥ prediction: I did not have breakfast üòÑ\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcac53f",
   "metadata": {},
   "source": [
    "Now you can try it on your own example! Write your own sentence below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef119cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is awesome üòÑ\n"
     ]
    }
   ],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_test = np.array(['Artificial Intelligence is awesome'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5951e7",
   "metadata": {},
   "source": [
    "* The current model still isn't very robust at understanding negation (such as \"not happy\")\n",
    "    * This is because the training set is small and doesn't have a lot of examples of negation. \n",
    "    * If the training set were larger, the LSTM model would be much better than the Emojify-V1 model at understanding more complex sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8a630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
